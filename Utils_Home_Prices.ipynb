{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floral-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import re\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metadata(df):\n",
    "    data = []\n",
    "    for feature in df.columns:\n",
    "        # Defining the role\n",
    "        if feature == 'target':\n",
    "            role = 'target'\n",
    "        elif feature == 'id':\n",
    "            role = 'id'\n",
    "        else:\n",
    "            role = 'input'\n",
    "\n",
    "            \n",
    "        # Defining the data type \n",
    "        dtype = df[feature].dtype\n",
    "\n",
    "        uniqueCnt = df[feature].nunique()\n",
    "        \n",
    "        # Defining the type\n",
    "        if (df[feature].dtype == 'datetime64[ns]') | (df[feature].dtypes == '<M8[ns]'):\n",
    "            type = 'datetime'\n",
    "        elif 'bin' in feature or feature == 'target':\n",
    "            type = 'binary'\n",
    "        elif 'cat' in feature or feature == 'id':\n",
    "            type = 'categorical'\n",
    "        elif (df[feature].dtype == 'float32') | (df[feature].dtype == 'float64'):\n",
    "            type = 'numeric'\n",
    "        elif (df[feature].dtype == 'int32') | (df[feature].dtype == 'int64'):\n",
    "            type = 'ordinal'\n",
    "        elif (df[feature].dtype == 'object'):\n",
    "            type = 'categorical'\n",
    "\n",
    "        if (uniqueCnt == 2 and type == 'ordinal'):\n",
    "            type = 'binary'\n",
    "\n",
    "\n",
    "        # Creating a dictionary for adding a row to metadata:\n",
    "        feature_dictionary = {\n",
    "            'varname': feature,\n",
    "            'role': role,\n",
    "            'type': type,\n",
    "            'dtype': dtype,\n",
    "            'uniqueCnt': uniqueCnt\n",
    "        }\n",
    "        data.append(feature_dictionary)\n",
    "\n",
    "    metadata = pd.DataFrame(data, columns=['varname', 'role', 'type', 'dtype', 'uniqueCnt'])\n",
    "    metadata.set_index('varname', inplace=True)\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def make_typedf(df, metadata, typeName):\n",
    "    cols = metadata[metadata['type']==typeName].index.tolist()\n",
    "    if 'id' in cols:\n",
    "        cols.remove('id')\n",
    "    \n",
    "    cnt = len(cols)\n",
    "    \n",
    "    res_df = pd.DataFrame(columns={'feature', 'uniqCnt', 'percentage'})\n",
    "    res_df['feature'] = cols\n",
    "\n",
    "    uniqLst = [df[col].nunique() for col in cols]\n",
    "    percentLst = [round(x*100/df.shape[0],2) for x in uniqLst]\n",
    "    \n",
    "    res_df['uniqCnt'] = uniqLst\n",
    "    res_df['percentage'] = percentLst\n",
    "    res_df.sort_values(by='uniqCnt', inplace=True, ignore_index=True)\n",
    "    \n",
    "    # To ensure the order of features in the dataframe:\n",
    "    res_df = res_df[['feature', 'uniqCnt', 'percentage']]\n",
    "    return cols, cnt, res_df\n",
    "\n",
    "def findSeason(dateCol, rowNumber):\n",
    "    \"\"\"\n",
    "    This function gets a list containing day of the year.\n",
    "    It returns a list of string equivalent to the season for each day in the input list.\n",
    "    \"\"\"\n",
    "    dayofYearLst = dateCol.dt.dayofyear\n",
    "    seasonLst = ['']*rowNumber\n",
    "\n",
    "    #to divide by season it's better to use the day of the year instead of the months\n",
    "    springLst = range(80, 172)\n",
    "    summerLst = range(172, 264)\n",
    "    fallLst = range(264, 355)\n",
    "    # winterLst = everything else\n",
    "    for i, x in enumerate(dayofYearLst):\n",
    "        if x in springLst:\n",
    "            season = 'Spring'\n",
    "        elif x in summerLst:\n",
    "            season = 'Summer'\n",
    "        elif x in fallLst:\n",
    "            season = 'Fall'\n",
    "        else:\n",
    "            season = 'Winter'\n",
    "        seasonLst[i] = season\n",
    "    return seasonLst\n",
    "\n",
    "def make_box_plot(df, cols):\n",
    "    cnt = len(cols)\n",
    "    if(cnt == 1):\n",
    "        col = cols[0]\n",
    "        fig, ax = plt.subplots(figsize=(5,3))\n",
    "        sns.boxplot(x=df[col], ax=ax);\n",
    "        #ax.set_title('Distribution')\n",
    "        ax.set_xlabel(col)\n",
    "    \n",
    "    else:\n",
    "        fig, axes = plt.subplots(cnt, 1, figsize=(5,3*cnt))\n",
    "        for i, col in enumerate(cols):\n",
    "            sns.boxplot(x=df[col], ax=axes[i]);\n",
    "            #axes[i].set_title('Distribution')\n",
    "            axes[i].set_xlabel(col)\n",
    "            #axes[i].set_ylabel('Count');\n",
    "        fig.tight_layout()\n",
    "    return None\n",
    "\n",
    "def make_binarybox_plot(df, cols, target, xRotation=0):\n",
    "    cnt = len(cols)\n",
    "    if(cnt == 1):\n",
    "        col = cols[0]\n",
    "        fig, ax = plt.subplots(figsize=(7,3))\n",
    "        sns.boxplot(x=df[col], y=df[target], ax=ax);\n",
    "        ax.set_title('{} Distribution'.format(target))\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('{} Range'.format(target));\n",
    "        if(xRotation != 0):\n",
    "            ax.tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "    \n",
    "    else:\n",
    "        xCnt = int(np.ceil(cnt/2))\n",
    "        fig, axes = plt.subplots(xCnt, 2, figsize=(12,4*xCnt))\n",
    "        for col, ax in zip(cols, axes.flatten()):\n",
    "            sns.boxplot(x=df[col],y=df[target], ax=ax);\n",
    "            ax.set_title('{} Distribution'.format(target))\n",
    "            ax.set_xlabel(col)\n",
    "            ax.set_ylabel('{} Range'.format(target));\n",
    "            if(xRotation != 0):\n",
    "                ax.tick_params(axis='x', labelrotation=90)\n",
    "            \n",
    "        fig.tight_layout()\n",
    "    return None\n",
    "        \n",
    "       \n",
    "def make_bar_plot(x, y,xLabel, yLabel, hue=None, xRotation = 0):\n",
    "    \"\"\"\n",
    "    This function will make a bar plot.\n",
    "    x: categorical or ordinal List,\n",
    "    y: Numerical list\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(5,3))\n",
    "    #if (hue != None):\n",
    "    sns.barplot(x=x, y=y, hue=hue, ax=ax);\n",
    "    ax.set_title('Distribution')\n",
    "    ax.set_xlabel(xLabel)\n",
    "    ax.set_ylabel(yLabel);\n",
    "    if(xRotation != 0):\n",
    "        ax.tick_params(axis='x', labelrotation=90)\n",
    "        \n",
    "def make_count_plot(df, cols, annotate=False, xRotation = 0, title=None):\n",
    "\n",
    "    totalcnt = df.shape[0]\n",
    "    cnt = len(cols)\n",
    "    if(cnt == 1):\n",
    "        fig, ax = plt.subplots(figsize=(5,3*cnt))\n",
    "        col = cols[0]\n",
    "        sns.countplot(x=df[col], ax=ax);\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Frequency');\n",
    "        \n",
    "\n",
    "        if(xRotation != 0):\n",
    "            ax.tick_params(axis='x', labelrotation=90)\n",
    "            \n",
    "        if(annotate == True):\n",
    "                for p in ax.patches:\n",
    "                    x=p.get_bbox().get_points()[:,0]\n",
    "                    y=p.get_bbox().get_points()[1,1]\n",
    "                    ax.annotate('{:.1f}%'.format(y*100/totalcnt), (x.mean(), y), ha='center', va='bottom')\n",
    "\n",
    "                    \n",
    "    \n",
    "    if(cnt>1):\n",
    "        fig, axes = plt.subplots(cnt, 1, figsize=(5,3*cnt))\n",
    "        for i, col in enumerate(cols):\n",
    "            sns.countplot(x=df[col], ax=axes[i]);\n",
    "            #axes[i].set_title('Distribution')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Frequency');\n",
    "            \n",
    "            \n",
    "            \n",
    "            if(xRotation != 0):\n",
    "                axes[i].tick_params(axis='x', labelrotation=90)\n",
    "            \n",
    "            if(annotate == True):\n",
    "                for p in axes[i].patches:\n",
    "                    x=p.get_bbox().get_points()[:,0]\n",
    "                    y=p.get_bbox().get_points()[1,1]\n",
    "                    axes[i].annotate('{:.1f}%'.format(y*100/totalcnt), (x.mean(), y), ha='center', va='bottom')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        \n",
    "        \n",
    "def removeOutliers_IQR(df, num_Feat, nIQR = 1.5, inplace=False ,imputation=0):\n",
    "    totalCnt = df.shape[0]\n",
    "    numeric_df = df[num_Feat]\n",
    "    nonNum_Feat = [col for col in df.columns if col not in num_Feat]\n",
    "    \n",
    "    q1 = numeric_df.quantile(.25)\n",
    "    q3 = numeric_df.quantile(.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = (q1 - nIQR * iqr)\n",
    "    upper = (q3 + nIQR * iqr)\n",
    "        \n",
    "#     if(imputation == 0):\n",
    "#         #new_df = num_df[~((new_df < lower)|(new_df > upper)).any(axis=1)]\n",
    "#         num_df = num_df[((num_df >lower) & (num_df <upper)).any(axis=1)]\n",
    "#         final_df = pd.concat([num_df, cat_df], axis=1)\n",
    "    \n",
    "    #dropped_df = numeric_df[((numeric_df < lower) | (numeric_df > upper)).any(axis=1)]    \n",
    "    dropped_df = df.loc[(numeric_df<lower) | (numeric_df>upper)]\n",
    "    droppedCnt = dropped_df.shape[0]\n",
    "    droppedPercent = 100 * droppedCnt / totalCnt\n",
    "    print('\\nFor nIQR = {:.2f}'.format(nIQR))\n",
    "    print('Count of dropped rows: {}'.format(droppedCnt))\n",
    "    print('Percentage of dropped rows: {:.3f}%'.format(droppedPercent))\n",
    "    \n",
    "    #print(numeric_df.loc[dropped_df.index].shape)\n",
    "    temp_df = df.copy(deep=True)\n",
    "    temp_df.drop(dropped_df.index, inplace = True)\n",
    "    if(inplace==True):\n",
    "        df.drop(dropped_df.index, inplace = True)\n",
    "    \n",
    "    return temp_df, dropped_df.index     \n",
    "\n",
    "\n",
    "\n",
    "def change_datatype(df): #minimize used memory\n",
    "    for col in list(df.select_dtypes(include=['int']).columns):\n",
    "        if df[col].max() < 2**7 and df[col].min() >= -2**7:\n",
    "            df[col] = df[col].astype(np.int8)\n",
    "        elif df[col].max() < 2**8 and df[col].min() >= 0:\n",
    "            df[col] = df[col].astype(np.uint8)\n",
    "        elif df[col].max() < 2**15 and df[col].min() >= -2**15:\n",
    "            df[col] = df[col].astype(np.int16)\n",
    "        elif df[col].max() < 2**16 and df[col].min() >= 0:\n",
    "            df[col] = df[col].astype(np.uint16)\n",
    "        elif df[col].max() < 2**31 and df[col].min() >= -2**31:\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "        elif df[col].max() < 2**32 and df[col].min() >= 0:\n",
    "            df[col] = df[col].astype(np.uint32)\n",
    "    for col in list(df.select_dtypes(include=['float']).columns):\n",
    "        df[col] = df[col].astype(np.float32)\n",
    "        \n",
    "\n",
    "def size_MB(obj):\n",
    "    import sys\n",
    "    size = sys.getsizeof(obj)\n",
    "    size /=10**6\n",
    "    size = round(size, 2)\n",
    "    return size\n",
    "\n",
    "\n",
    "def miss_value_func(in_data, classificatio_flag=0, only_miss_col=0):\n",
    "    \"\"\"\n",
    "    The dataframe is supposed to have target column with name of 'target'.\n",
    "    \"\"\"\n",
    "    out_table = pd.DataFrame(in_data.isnull().sum(), columns = ['miss_value'])\n",
    "    out_table['percentage'] = (100 * out_table['miss_value'])/len(in_data)\n",
    "    out_table.sort_values(by='miss_value', ascending=False, inplace=True)\n",
    "\n",
    "    lst_miss_col = [i for i in range(len(out_table)) if (out_table.iloc[i][1]!=0)]    \n",
    "    print('The input data frame has {:d} features.'.format(in_data.shape[1]))\n",
    "    print('The data frame has {:d} columns with missing values'.format(len(lst_miss_col)))\n",
    "    \n",
    "    \n",
    "    if(only_miss_col == 1):\n",
    "        len_miss = len(lst_miss_col)\n",
    "        out_table = out_table.iloc[:len_miss, :]\n",
    "    if (classificatio_flag == 0):\n",
    "        return out_table\n",
    "    \n",
    "    if classificatio_flag == 1:\n",
    "        try:\n",
    "            uniq_levels = list(in_data['target'].unique())\n",
    "            uniq_n = len(uniq_levels)\n",
    "            n_total = len(in_data)\n",
    "            n_target1 = len(in_data[in_data['target']==1])\n",
    "            n_target0 = n_total - n_target1\n",
    "            flag=1\n",
    "        except:\n",
    "            print(\"Error!  The dataframe does not have column with name 'target'.  Try again...\")\n",
    "            flag = 0\n",
    "        \n",
    "        if flag == 1:\n",
    "            \n",
    "            for lev in uniq_levels:\n",
    "                str_col = 'count_miss: target=' + str(lev)\n",
    "                out_table[str_col] = 0 \n",
    "            \n",
    "            for lev in uniq_levels:\n",
    "                str_col = 'percent_miss: target=' + str(lev)\n",
    "                out_table[str_col] = 0 \n",
    "                \n",
    "            for lev in uniq_levels:\n",
    "                str_col = 'norm_miss: target=' + str(lev)\n",
    "                out_table[str_col] = 0 \n",
    "            \n",
    "            len_miss = len(lst_miss_col)\n",
    "            for i, col in enumerate(lst_miss_col):\n",
    "                for j, lev in enumerate(uniq_levels):\n",
    "                    count = in_data[out_table.index[i]][in_data['target']==lev].to_frame().isnull().sum()\n",
    "                    percent = (count / out_table.iloc[i, 0])*100\n",
    "                    out_table.iloc[i, 2+j] = count[0]\n",
    "                    out_table.iloc[i, 2+j+uniq_n] = percent[0]\n",
    "                    if(lev == 0):\n",
    "                        out_table.iloc[i, 2+j+2*uniq_n] = 100*(count[0]/n_target0)\n",
    "                    elif(lev== 1):\n",
    "                        out_table.iloc[i, 2+j+2*uniq_n] = 100*(count[0]/n_target1)\n",
    "            return out_table\n",
    "\n",
    "        \n",
    "def add_missCol(df):\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    length = df.shape[0]\n",
    "    missLst = [0]*length\n",
    "    for row in range(length):\n",
    "        missCnt = 0\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                x = float(df.loc[row, col])\n",
    "                if(x!=x):\n",
    "                    missCnt +=1  \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if col == 'count':\n",
    "                missLst[row] = missCnt\n",
    "    df['misscnt'] = missLst\n",
    "    return True#df\n",
    "\n",
    "\n",
    "def check_numCols(df, cols):\n",
    "    # This function checks if all columns are numerical or not. \n",
    "    # Finally, if there are some columns which are not numerical, they will return.\n",
    "    resType = [df[col].dtype for col in cols]\n",
    "    res = [col for i,col in enumerate(cols) if resType[i] == 'O']\n",
    "    if(len(res)>0):\n",
    "        print('Notice!!!\\n')\n",
    "        print('The following columns are not pure numerical. They have some non-numericla data.')\n",
    "        print(res)\n",
    "    else:\n",
    "        print('Verified!')\n",
    "        print('All columns are pure numerical.')\n",
    "    return df, res\n",
    "\n",
    "def convert_check_numCols(df, cols, distributionFlag=False):\n",
    "    # This function will convert passed columns into numerical.\n",
    "    # Finally, if there are some columns which are remained in form of object datatype, they will return.\n",
    "    \n",
    "    # First, we will change datatype into numeric:\n",
    "    for col in cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "    \n",
    "    resType = [df[col].dtype for col in cols]\n",
    "    catCols = [col for i,col in enumerate(cols) if resType[i] == 'O']# We will save features having nonnumerical data.\n",
    "    \n",
    "    if(len(catCols)==0):\n",
    "        print('All columns are verified; 100% numerical')\n",
    "        return\n",
    "    \n",
    "    elif(len(catCols)>0):        \n",
    "        print('Notice!!!\\n')\n",
    "        print('The following columns are not pure numerical. They have some non-numericla data.')\n",
    "        print(catCols)\n",
    "\n",
    "        # We will save index of data which are not numerical in indexLst.\n",
    "        indexLst = []\n",
    "        \n",
    "        # We keep the info in colLst and rowLst for printing in dataframe.\n",
    "        colLst = ['Feature', 'NonNumerical %']\n",
    "        rowLst = []\n",
    "    \n",
    "        for col in catCols:\n",
    "            if(df[col].dtype == 'O'):\n",
    "                check_status = df[col].apply(lambda x: x.isnumeric())\n",
    "            else:\n",
    "                check_status = df[col].apply(lambda x: x.str.isnumeric())\n",
    "            \n",
    "            catIndex = check_status.loc[check_status == False].index\n",
    "            if(len(catIndex>0)):\n",
    "                indexLst.append(catIndex)\n",
    "                nonNumericalValue = round(len(catIndex)*100/df.shape[0], 2)\n",
    "                valueLst = [col, nonNumericalValue]\n",
    "                dic1 = {k:v for k,v in zip(colLst, valueLst)}\n",
    "                rowLst.append(dic1)# Will save nonnumerical data for adding into dataframe\n",
    "                \n",
    "                if(distributionFlag == True):\n",
    "                    print('The distribution of nonnumerical data of \"{}\" is as follow:'.format(col))\n",
    "                    print(df.loc[catIndex, col].value_counts())\n",
    "                    print('********************************************************')\n",
    "        \n",
    "        res_df = pd.DataFrame(rowLst, columns = colLst)\n",
    "    return df, catCols, res_df, indexLst\n",
    "\n",
    "\n",
    "def analyze_prediction(y_predicted, y_observed, result_matrix = None, model_name=None):\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true=y_observed, y_pred=y_predicted))\n",
    "    r2 = r2_score(y_true=y_observed, y_pred=y_predicted)\n",
    "    \n",
    "    if (model_name != None):\n",
    "        result_matrix.loc['R2', model_name] = r2\n",
    "        result_matrix.loc['RMSE', model_name] = rmse\n",
    "        \n",
    "\n",
    "    print(\"R2, RMSE:\")\n",
    "    return r2, rmse\n",
    "\n",
    "\n",
    "def makeHeatmap(df, cols, annot = False, line=False):\n",
    "    #colormap = plt.cm.white\n",
    "    colormap = plt.cm.YlGnBu\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.title('Correlation Heatmap', size=15)\n",
    "    if(line == True):\n",
    "        sns.heatmap(df[cols].corr(), vmax=1.0, cmap=colormap, annot=annot, square=True, linewidths=0.005, linecolor='gray');\n",
    "    elif(line == False):\n",
    "        sns.heatmap(df[cols].corr(), vmax=1.0, cmap=colormap, annot=annot, square=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
